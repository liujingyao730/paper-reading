# GCN相关的基础文献
图卷积网络是针对于图结构数据的有力分析工具，这四篇文章是图卷积网络领域内比较重要的基础性工作，对于我们理解和使用图卷积网络有着很重要的意义
## 目录
* [谱视角(Spectral method)](#谱视角)
    * [before deep learing graph neural network](#图卷积)
    * [convolutional neural networks on graphs with fast localized spectral filtering](#图卷积的快速计算)
    * [Semi-supervised classification with graph convolutional network-iclr2017](#一阶近似与半监督学习)
    * [Deeper insights into graph convolutional networks for semi-supervised learning aaai2018](#deeper-insights)
    * [Diffusion convolutional recurrent neural network Data-driven traffic forecasting](#扩散卷积)
* [空间视角(spatial method)](#空间视角)
    * [Geometric deep learning on graphs and manifolds using mixture model CNNs CVPR2017](#一般化的框架)
    * [Inductive Representation Learning on Large Graphs](#推断式的图卷积)
## 谱视角
### 图卷积
在Euclidean domains(图像，声音信号等类型)的数据中，卷积操作就是将函数进行傅里叶变换映射到频域空间，之后进行相乘再做逆傅里叶变换得到的结果。对于图结构的数据，如果我们想要将卷积领域进行扩展，就需要合理的定义在图领域的傅里叶变换，进而可以定义图领域的卷积操作。  
把Euclidean domains中的傅里叶变换迁移拓展到图领域中，最核心的步骤在于把拉普拉斯算子的特征函数$e^{i\omega t}$在图领域中做出对应的映射，而这个对应的映射就是图拉普拉斯矩阵的特征向量
* 传统领域的傅里叶变换  <div id='label'>
  
> 传统的傅里叶变换定义为：$F(\omega)=\mathcal{F}[f(t)]=\int f(t)e^{i\omega t}dt$，这是信号$f(t)$与基函数$e^{i\omega t}dt$之间的积分，而基函数选择它的原因在于$e^{i\omega t}dt$是拉普拉斯算子的特征函数  
> 同样的，当我们想将卷积拓展到图领域时，因为图的拉普拉斯矩阵就是离散的拉普拉斯算子，所对应的选择的基函数就应当是图拉普拉斯矩阵的特征向量

* 图拉普拉斯矩阵的定义与分解

> 图的拉普拉斯矩阵通常定义为$L=D-A，$其中$D$指顶点度数组成的对角矩阵，$A$指邻接矩阵或者边权重矩阵；在运算中通常采用归一化后的拉普拉斯矩阵$L^{sys} = D^{-1/2}LD^{-1/2}$
> 图拉普拉斯矩阵是对称半正定矩阵，它的特征向量之间相互正交，所有的特征向量构成的矩阵成为正交矩阵，因此我们可以知道拉普拉斯矩阵一定可以进行谱分解，并且分解后有特殊的形式：
> $$L=U \left[ \begin{matrix}\lambda_1 & & \\ & ... & \\ & & \lambda_n\end{matrix}\right]U^T$$
> 其中$U$是由拉普拉斯矩阵特征向量组成的矩阵，而$\lambda$代表着拉普拉斯矩阵的特征值

* 图领域的傅里叶变换
> 仿照传统领域下的傅里叶变换定义，我们就可以得到图领域的傅里叶变换
> $$ F(\lambda_l)=\hat{f}(\lambda_l)=\sum^N_{i=1}f(i)u^*_l(i)$$
> $f$是图上的N维向量，$f(i)$表示节点i上对应的输入，$u_l(i)$表示第$l$个特征向量的第$i$个分量，特征值就对应了在不同基函数下对应的分量，也可以在一定程度上认为是对应的频率。$f$的图傅里叶变换就是与$\lambda_l$对应的特征向量$u_l$进行内积运算
> 进一步的，我们图傅里叶变换的矩阵形式写成：
> $$ \left[ \begin{matrix} 
> \hat f(\lambda_1) \\
> \hat f(\lambda_2) \\
> \vdots\\
> \hat f(\lambda_N) 
> \end{matrix} \right] = 
> \left[ \begin{matrix} 
> u_1(1) & u_1(2) & \cdots & u_1(N) \\
> u_2(2) & u_2(2) & \cdots & u_N(2) \\
> \vdots & \vdots & \ddots & \vdots \\
> u_1(N) & u_2(N) & \cdots & u_N(N)
> \end{matrix} \right]
> \left[\begin{matrix}
> \hat f(\lambda_1) \\
> \hat f(\lambda_2) \\
> \vdots\\
> \hat f(\lambda_N)
> \end{matrix}\right] $$
> 也就是说$\hat{f}=U^Tf$，逆傅里叶变换也可同样的形式推广：$f=U\hat{f}$

* 图卷积
> 对于卷积核$h$，我们将其进行傅里叶变换之后的结果写成对角矩阵的形式就是：$g(\Lambda)=diag(\hat{h}(\lambda_1), \hat{h}(\lambda_2),...,\hat{h}(\lambda_N))$，所以$h与f$的卷积就可以写成：
> $$f*_gh= Ug(\Lambda)U^Tf$$
### 图卷积的快速计算
回顾传统二维图像中的卷积，我们可以发现二维的卷积具备着两个很好的特性：
* 局部连接：每一个卷积核在不同的位置只对这一个位置的局部具备感受的能力，不接收其他区域的信息
* 参数共享：每一个卷积核在不同的位置都使用相同的参数，这就极大的减少了所需学习的参数数量

但是在上述图卷积的操作中这两点都不具备，每一个卷积核所需要学习的参数$g(\Lambda)=diag(\hat{h}(\lambda_1), \hat{h}(\lambda_2),...,\hat{h}(\lambda_N))$的规模为$\mathcal{O}(N)$，$N$表示节点数目，在多通道，多卷积核的情况下参数的数目相当的庞大；另外在这样的操作下就意味着每一个节点都可以看到所有的节点的信息，这样就不具备局部连接的特性  
因此，为了适应深度学习的需求，学者们对图卷积做了一定程度的改变使得它具备了局部感知特性并且降低了参数数量：
#### Polynomial parametrization for localized filters  
多项式参数化就是将原本作为卷积核参数的对角矩阵，由简单的学习对角矩阵对角线上每一个元素改变成学习一个多项式的系数，即：
$$g(\Lambda)=diag(\theta_1, \theta_2,...,\theta_N) \rightarrow g(\Lambda)=\sum_i^{K-1}\theta_i\Lambda^k$$
这样原本的卷积操作就变成：
$$\begin{aligned}
    f *_g h =& Ug(\Lambda)U^Tf\\
    =&U(\sum_i^{K-1}\theta_i\Lambda^k)U^Tf\\
    =&(\sum_i^{K-1}\theta_iL^k)f
\end{aligned}$$
这样就将原本的参数量从$\mathcal{O}(N)$降低到了$\mathcal{O}(K)$，同时由于拉普拉斯矩阵的特殊性，$K$具备着明确的含义，即每一个节点所能看到的节点的最近距离，这样就达到了降低参数量同时使得卷积核具备了局部连接性的目的
#### Recursive formulation for fast filtering
在进行了上述的变化之后，虽然降低了整体的参数量也避免了拉普拉斯矩阵的特征值分解计算，但在实际的计算中计算代价仍然不小（拉普拉斯矩阵的分解步骤可以在训练前就分解完成，整体更新参数时只要调用分解完成的特征向量矩阵即可，而同时因为需要计算拉普拉斯矩阵的乘积，空间存储本身的复杂度就在$\mathcal{O}(N^2)$级别，所以整体避免分解只是略微降低了空间复杂度）  
因此，为了避免$\mathcal{O}(N^3)$的矩阵乘（虽然在算法层面有更快级别的算法），作者提出采用切比雪夫多项式逼近的方法来通过递归计算拉普拉斯矩阵乘向量的方式降低计算的复杂度，即：
$$g(\Lambda)=\sum_i^{K-1}\theta_i\Lambda^i\approx\sum_i^{K-1}\theta_iT_i(\tilde{L})$$
其中$\tilde{L}=2L/\lambda_{max} - I_N$这是为了保证切比雪夫多项式的数学性质而做出的变换，切比雪夫多项式的计算公式为：$T_k(L)=2xT_{k-1}(x)-T_{k-1}(x), T_1(x)=x, T_0(x)=1$，这样，如果我们将$T_i(\tilde{L})f$记做$x_k$的话，卷积操作就变成$f *_g h=\sum_i^{K-1}x_i$，而每一个$x_i$可以通过$x_i = 2\tilde{L}x_{i-1}-x_{i-2}$的方式递归计算得到，而由于拉普拉斯矩阵是一个稀疏矩阵，那么整体的计算复杂度就降低到$\mathcal{O}(\mathcal{E})$，$\mathcal{E}$表示边的数量，这样就大大的降低的计算的复杂度，使得图卷积操作适应了深度学习的要求
#### Fast Pooling of Graph Signals
进一步地，在图卷积中我们可以构建一个类似于池化的操作，把相近似的节点相互聚合起来，这样的操作需要满足两点：1）我们需要可以控制，或者明确知道每一轮类比的池化操作之后图会缩减成什么尺寸；2）类比的池化操作需要可以快速的实现，最好可以容易的并行化计算，这样就可以进行加速。
首先我们需要介绍一下Graclus multilevel clustering算法，这是一个基于贪心规则的算法，具体的步骤是，在未标记的点中选中一个，然后在它未被标记的邻接节点中选取可以最大化$W_{ij}(\frac{1}{d_i}+\frac{1}{d_j})$ 的节点，将这两个节点合并成一个，把他们的与其他节点的边权重加和作为新节点的边权重，重复直至所有的节点都探索，这样整体上图的大小会被缩小一半（会有一些单独节点singleton的存在）
在实际的计算中，为了便于并行化与快速的计算，整体上通过平衡二叉树的方式将节点之间在不同层级的合并关系组织起来，具体来说就是：1）每一层的节点都是前一层合并而来的两个的父节点；2）单子节点(singleton)将会配备一个虚拟节点与它一起作为下一层父节点的兄弟节点，每一个虚拟节点都设置成为中性值(neutral value)，也就是0，这样以ReLU函数作为激活函数同时通过max pooling的方式就不会因为添加了虚拟节点而造成影响：
![fast pooling](../pics/fast_pooling.png)
### 一阶近似与半监督学习
有了前面的基础之后，学者们进一步提出了更加简化的图卷积框架，在上述的图卷积操作$g(\Lambda)x=\sum_i^{K-1}\theta_iT_i(\tilde{L})x$中，如果我们将$K$的值限定为2，在实际卷积中就意味着每个节点只能看到与自己邻接的节点信息，图卷积的操作就会变为：
$$g(\Lambda)x=\theta_0x+\theta_1\tilde{L}x$$
因为神经网络中对数据的尺度变换和归一化操作，我们可以进一步假设$\lambda_{max}\approx2$，再加上这里我们使用的是拉普拉斯矩阵的归一化形式:$L=I_n-D^{-1/2}AD^{-1/2}$那么我们可以将上式进一步简化为：
$$g(\Lambda)x=\theta_0x+\theta_1(L-I_n)x=\theta_0x-D^{-1/2}AD^{-1/2}\theta_1x$$
再进一步地，为了简化参数这里指定$\theta_0=-\theta_1=\theta$上式就简化为:
$$g(\Lambda)x=\theta(I_n+D^{-1/2}AD^{-1/2})x$$
随后文章进行了进一步的化简，为了方便下一节讲述deeper insights，这里就不再进一步化简，详细的化简参见文章内容
有了这样的图卷积操作，就可以进行快速的半监督学习，具体的方法就是当网络最后的输出之后，只对有标记的节点计算交叉熵损失，然后进行梯度回传更新网络参数，输出时预测所有节点类别
### deeper-insights
为什么GCN可以取得很好的效果呢？当我们卷积操作$g(\Lambda)x=\theta(I_n+D^{-1/2}AD^{-1/2})x$聚焦在单一的某个节点时，就会得到：

$$h^r_i=\theta(h^{r-1}_i+\sum_{j\in\mathcal{N}(i)}\frac{h_j^{r-1}}{\sqrt{d_id_j}})$$

这就是另外一种形式的拉普拉斯平滑，这样的平滑本质上的含义在于，每一个节点与自己相邻近节点相近似，每一层的图卷积会让每一个节点与自己相近的节点（也更大可能上是处于同一类别的节点）交换信息，这也就是为什么图卷积网络在半监督学习中会取得较好结果的原因
但是图卷积网络与传统卷积网络不同的一点在于，并不是越深层的卷积层数就会带来更好的效果，事实上，在半监督分类问题中，层数过多会降低整体网络效果：
![卷积网络层数与分类问题](../pics/gcn_layer.png)
这源自于拉普拉斯平滑本身的特性，快速的进行连续几层的拉普拉斯平滑会导致图中联通区域内的节点的值趋于一致。
而这样的特性本身限制了图卷积网络的效果，深层的网络会导致过度平滑而使得连通区域趋于一致，但浅层的网络并不能使节点充分利用到整个图的信息，在这篇文章中作者提出了一种联合训练的方式来避免在深层图卷积网络中带来的过度平滑的问题，同时又可以通过深层的网络将信息传播到整个图中。
文章的思路是只用浅层的图卷积（一般是两层），然后通过自训练与随机游走过程的联合训练的方式增强在半监督学习中的效果。
##### 随机游走模型：
根据选定的随机游走模型来确定，确定下来随机游走的分布矩阵$\mathcal{P}$，其中$\mathcal{P}_{ij}$表示从第$i$个节点随机游走到第$j$节点终止的分布概率，这样我们就可以根据这个随机游走分布矩阵$\mathcal{P}$，针对每一个类别$k$，可以计算一个置信度向量
$$\textbf{p}=\sum_{j\in\mathcal{S}_k}\mathcal{P}_{:,j}$$
其中$\textbf{p}_i$是第$i$个节点属于第$k$类的置信度，在这个向量中选取出前$k$项，作为半监督学习中补充的被标记数据，作为扩张的数据集
##### 自训练过程
自训练过程是指在卷积训练中，会根据图卷积网络的输出结果，计算所有类别中前k项置信度最高的作为补充被标记数据集
通过取这两个过程的并集，模型在半监督学习分类问题中取得了最好的效果
### 扩散卷积
扩散卷积(Diffusion Convolutional)是根据随机游走过程而实现的一种图卷积的形式，这种形式的图卷积就是将图中信息传递的过程与随机游走过程类比，随机游走过程就是我们假设从一个节点$i$出发，以一定规律随机选取周围的节点进行游走，同时以一定概率$\alpha$终止，如果下一步节点选取的方式是均匀随机选取，那么就会有得到一个随机游走最终结果的分布矩阵：
$$\mathcal{P}=\sum_{i=0}^{\infty}\alpha(1-\alpha)^i(D_O^{-1}W)^i$$
其中$D_o$是节点的出度组成的对角矩阵，仿照这个过程就可以得到扩散卷积的计算方式：
$$\textbf{X}_{:,p}*_{\mathcal{G}}f_{\theta}=\sum_{k=0}^{K-1}(\theta_{k,1}(D_o^{-1}W)^k+\theta_{k,2}(D_i^{-1}W)^k)\textbf{X}_{:,p}$$
这样的图卷积替代传统的图卷积在GCRNN中的作用会得到更好的效果

## 空间视角
以上的内容都是来自于从谱视角进行的对图特征的提取，这种方法下的图卷积有着严密的数学推导与很好的实验效果，但是一个严峻的问题就在于这样的图卷积操作依赖于图的拉普拉斯矩阵，当图的结构发生变化时往往不能进行很好的泛化，就如下图中展示的：
![拉普拉斯矩阵与图卷积结果](../pics/拉普拉斯矩阵变换.png)
传统的图卷积(LeNet)与在固定的图结构(前两行)下学习得到的图卷积网络(ChebNet)都取得了很好的效果，但是当数据变成从超像素中提取的时候，因为这是不同图片之间根据超像素算法所提取到的图结构并不相同，就导致了图的结构发生了变化，这是传统的图卷积的准确率产生了严重的下滑，最多下降到75%左右，因此一种不依赖于拉普拉矩阵的图卷积算法需要被探索和研究，这就是空间视角下的图卷积方式
### 一般化的框架
在这篇CVPR2017年的文章中，提出了一般化的可以用于泛化卷积操作的框架，在这个框架之下可以通过设置不同的伪坐标(pseudo-coordinate)形式，与权重计算函数就可以实现对不同形式的卷积。在这个框架之下，可以实现之前各种对于图的卷积与对于流形的卷积
我们将需要进行卷积的输入（图像，音频，图结构的数据，流形等）上的一个节点记做$x$，在不同的输入情况下，我们都考虑节点$y\in\mathcal{N}(x)$，其中$\mathcal{N}(x)$表示$x$的邻域节点，包括$x$本身。对于每一个$y$都可以专门设计出一种伪坐标形式$\textbf{u}(x, y)$，针对不同的伪坐标值，设计出权值计算函数（也可以叫卷积核）：$\textbf{w}_{\Theta}(\textbf{u})=(w_1(\textbf{u}),......,w_J(\textbf{u})))$，权值函数由一些可学习的参数$\Theta$确定，每一个局部的卷积操作表示为：
$$D_j(x)f=\sum_{j\in\mathcal{N}(x)}w_j(\textbf{u}(x,y))f(y),\quad j=1,...,J$$
那么整体上在非欧几里得空间下的卷积形式就可以写作：
$$(f*g)(x)=\sum^J_{j=1}g_jD_j(x)f$$
在这个框架设计中，最关键的步骤是伪坐标的确定与权值函数的计算，以下是一些卷积形式在本文框架之下的具体设定：
![坐标与权重函数在不同卷积形式下的体现](../pics/general_frame_work.png)
上式中GCNN与ACNN是应用于流形之中的卷积形式，GCN是前面描述的基于谱视角下的卷积，DCNN是扩散卷积
在这篇文章中，在总结出整体一般化的框架之后，提出了自己所实现的卷积操作，这种卷积操作并没有采用人工设置固定的权重计算函数，而是选择了一种可以通过训练而不断更新的权值计算函数：
$$w_j(\textbf{u})=\exp(-\frac{1}{2}(\textbf{u}-\mu_j)^T\Sigma^{-1}(\textbf{u}-\mu_j))$$
上式中$\mu_j,\Sigma$是需要学习的参数，其中为了降低学习的难度，$\Sigma$限制为对角矩阵，这样的情况下就已经足够提供相当的函数复杂度以达到更好的模型效果。如果要追求更加输入的更高维表示，可以通过在坐标值输入网络之前进行相应的非线性变换达到。在不同的应用中采取不同的坐标形式，搭配上式表示的权值计算函数就可以得到比以往模型更好的效果。
当我们仔细观察这个权值计算函数，就会发现这是多维高斯分布的一种形式，前述的非欧空间内的卷积就可以解释为一种高斯混合模型，通过学习一种能够描述节点周围相关性的高斯混合模型来合理的分配对周围节点信息的接纳程度。
### 推断式的图卷积
谱视角下，图的结构是固定的，对于图中没有出现过的节点，甚至是全新的图时，原有训练得到的卷积核参数往往不能很好的适应图的变化，因此这篇文章提出了一种可以进行推断式任务的图卷积模型：GraphSAGE(Graph SAmple aggerGatE)
这种模型不同于之前图卷积方面的方法，直接通过学习的方式得到每一个节点在下一层的隐层状态向量，而是学习不同的AGGERGATE函数用来收集不同跳步数或者搜索深度的信息，在测试阶段直接应用这些训练好的AGGERGATE函数对没有出现过的节点应用，文中提出了非监督的学习方式，但本文的模型同样也能适用于监督学习的训练方式
首先我们看一下整体算法的流程：
![GraphSAGE算法流程](../pics/alg_graphsage.png)
这个算法的具体含义就是，对不同搜索深度的邻域节点，采用不同的AGGREGATE函数进行信息收集，将从周围节点收集到的信息，通过拼接的方式与之前深度的信息进行融合